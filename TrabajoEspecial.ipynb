{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se len los datos del archivo, corrigiendo el formato de separacion, de ';' a ','."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_dataset = pd.read_csv('Calidad_de_agus_2023.csv', delimiter=';')\n",
    "\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un head para ver de que tratan los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos las columas orden, codigo y año ya que no aportan nada al analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = raw_dataset.drop('orden', axis=1)\n",
    "raw_dataset = raw_dataset.drop('codigo', axis=1)\n",
    "raw_dataset = raw_dataset.drop('año', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en busca de nulos por columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos en cada una de las columnas que valores toman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se revisa una por una las columnas\n",
    "#lo que esta entre corchetes se fue cambiando entre todas las variables para ver que valores aparecen\n",
    "\n",
    "for idx, val in raw_dataset[\"od\"].value_counts().items():\n",
    "  print(idx, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplazamos por nulos los valores que no nos interesan, es decir, no nos aportan informacion relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Copiar el dataset\n",
    "preprocessed_dataset = raw_dataset.copy()\n",
    "\n",
    "# Lista de valores a reemplazar por pd.NA\n",
    "valores_a_reemplazar = ['sin equipo', 'no muestreó', 'no se midió', 'en obra', 'no se muestreó',\n",
    "                        'inaccesible', 'sin muestra', 'envase sin muestra', 'falto un frasco',\n",
    "                        'Dato atípico', 'no se pudo calcular', 'N/R', 'no funcionó', '-', 'N/A', '', ' ']\n",
    "\n",
    "# Lista de columnas a las que se les debe aplicar el reemplazo\n",
    "columnas_a_procesar = [\n",
    "    'tem_agua', 'tem_aire', 'od', 'ph', 'olores', 'color', 'espumas', 'mat_susp', \n",
    "    'colif_fecales_ufc_100ml', 'escher_coli_ufc_100ml', 'enteroc_ufc_100ml', \n",
    "    'nitrato_mg_l', 'nh4_mg_l', 'p_total_l_mg_l', 'fosf_ortofos_mg_l', \n",
    "    'dbo_mg_l', 'dqo_mg_l', 'turbiedad_ntu', 'hidr_deriv_petr_ug_l', 'cr_total_mg_l',\n",
    "    'cd_total_mg_l', 'clorofila_a_ug_l', 'microcistina_ug_l', 'ica', 'calidad_de_agua'\n",
    "]\n",
    "\n",
    "# Recorrer todas las columnas y aplicar el reemplazo\n",
    "for columna in columnas_a_procesar:\n",
    "    preprocessed_dataset[columna] = preprocessed_dataset[columna].replace(valores_a_reemplazar, pd.NA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a borrar aquellas filas que quedaron con muchos nulos, ya que no nos van a servir para el analisis. Estas filas borradas son aquellas con mas de 23 valores nulos, que corresponden a las muestras donde no se realizaron observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_dataset = preprocessed_dataset.dropna(thresh=len(preprocessed_dataset.columns) - 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego definimos las columnas que van a ser de tipo cuantitativos y de fecha, eliminando los simbolos \"<\" o \">\" en los valores que los porten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_convertir = ['tem_agua', 'tem_aire', 'od', 'ph', 'colif_fecales_ufc_100ml',\n",
    "                         'escher_coli_ufc_100ml', 'enteroc_ufc_100ml', 'nitrato_mg_l', 'nh4_mg_l',\n",
    "                         'p_total_l_mg_l', 'fosf_ortofos_mg_l', 'dbo_mg_l', 'dqo_mg_l', 'turbiedad_ntu',\n",
    "                         'hidr_deriv_petr_ug_l', 'cr_total_mg_l', 'cd_total_mg_l', 'clorofila_a_ug_l',\n",
    "                         'microcistina_ug_l', 'ica']\n",
    "\n",
    "for col in columnas_a_convertir:\n",
    "    preprocessed_dataset[col] = preprocessed_dataset[col].str.replace('<', '').str.replace('>', '')\n",
    "    preprocessed_dataset[col] = pd.to_numeric(preprocessed_dataset[col])\n",
    "\n",
    "preprocessed_dataset['fecha'] = pd.to_datetime(preprocessed_dataset['fecha'], format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos el tipo de dato de determinadas columnas para poder trabajar con las variables cualitativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformacion campaña\n",
    "preprocessed_dataset['campaña']=preprocessed_dataset['campaña'].replace(['Verano','otoño','invierno','primavera'],['0','1','2','3'])\n",
    "\n",
    "#transformacion olores, color, espumas,mat_susp\n",
    "preprocessed_dataset['olores']=preprocessed_dataset['olores'].replace(['Ausencia','Presencia'],['0','1'])\n",
    "preprocessed_dataset['color']=preprocessed_dataset['color'].replace(['Ausencia','Presencia'],['0','1'])\n",
    "preprocessed_dataset['espumas']=preprocessed_dataset['espumas'].replace(['Ausencia','Presencia'],['0','1'])\n",
    "preprocessed_dataset['mat_susp']=preprocessed_dataset['mat_susp'].replace(['Ausencia','Presencia'],['0','1'])\n",
    "\n",
    "#transformacion calidad_de_agua\n",
    "preprocessed_dataset['calidad_de_agua']=preprocessed_dataset['calidad_de_agua'].replace(['Muy deteriorada','Muy deteriorada ','Extremadamente deteriorada'],['0','0','1'])\n",
    "\n",
    "columnas_cualitativas = ['campaña', 'olores', 'color', 'espumas', 'mat_susp', 'calidad_de_agua']\n",
    "preprocessed_dataset[columnas_cualitativas] = preprocessed_dataset[columnas_cualitativas].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el porcentaje de nulos en cada columna para ver si las eliminabamos. Como en ninguna de las columnas hay presencia de nulos mayor o igual al 60% las conservamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_totales = columnas_a_convertir.copy()\n",
    "columnas_totales.extend(columnas_cualitativas)\n",
    "\n",
    "for col in columnas_totales:\n",
    "    if ((preprocessed_dataset[col].isna().sum() / len(preprocessed_dataset[col]))*100 >= 60):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a la columna, realizamos imputaciones con la tecnica de los n vecinos mas cercanos, eligiendo los dos mas cercanos, para suprimir los valores nulos restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sabemos si esto es correcto al no haber analizado los mecanismos de datos faltantes, por desconcer el dominio del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 2, weights = \"uniform\")\n",
    "\n",
    "\n",
    "preprocessed_dataset_imputado = preprocessed_dataset[columnas_totales]\n",
    "dataset_imputado = imputer.fit_transform(preprocessed_dataset_imputado)\n",
    "\n",
    "preprocessed_dataset[columnas_totales] = dataset_imputado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
